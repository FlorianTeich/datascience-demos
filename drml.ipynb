{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5002f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn pandas numpy matplotlib plotly \"nbformat>=4.2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91371aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0b905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# generate random data\n",
    "SAMPLES = 1000\n",
    "x, y = make_classification(n_samples=SAMPLES, n_features=20, n_informative=15, random_state=42, n_classes=2)\n",
    "# select 20% of the data for later testing\n",
    "test_split_x = x[:int(SAMPLES * 0.2)]\n",
    "test_split_y = y[:int(SAMPLES * 0.2)]\n",
    "train_split_x = x[int(SAMPLES * 0.2):]\n",
    "train_split_y = y[int(SAMPLES * 0.2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55141b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data_selection_model = MLPClassifier(hidden_layer_sizes=(10), max_iter=50, random_state=42)\n",
    "labeled_data_selection_model.fit(x, y)\n",
    "scores = labeled_data_selection_model.predict_proba(train_split_x)\n",
    "scores = scores[:, 1]  # get probabilities for the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d93a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the samples via pca:\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_x = pca.fit_transform(x)\n",
    "pca_test_split_x = pca.transform(test_split_x)\n",
    "pca_train_split_x = pca.transform(train_split_x)\n",
    "fig = px.scatter(x=pca_x[:, 0], y=pca_x[:, 1], color=y, title=\"PCA of the data\")\n",
    "fig.add_trace(go.Scatter(x=pca_test_split_x[:, 0], y=pca_test_split_x[:, 1], mode='markers', name='Test Data', marker=dict(color='red', size=5, symbol='cross')))\n",
    "fig.add_trace(go.Scatter(x=pca_train_split_x[:, 0], y=pca_train_split_x[:, 1], mode='markers', name='Train Data', marker=dict(color='blue', size=5, symbol='circle')))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ece60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot of the score distribution\n",
    "fig = px.histogram(pd.Series(scores), nbins=50, title='Score Distribution', labels={'value': 'Score'})\n",
    "fig.update_layout(xaxis_title='Score', yaxis_title='Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca421442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find threshold such that 5% of the data is above it\n",
    "threshold_above = np.percentile(scores, 95)\n",
    "threshold_below = np.percentile(scores, 5)\n",
    "# filter data above the threshold\n",
    "x_above = train_split_x[scores >= threshold_above]\n",
    "y_above = train_split_y[scores >= threshold_above]\n",
    "x_below = train_split_x[scores <= threshold_below]\n",
    "y_below = train_split_y[scores <= threshold_below]\n",
    "\n",
    "labeled_data_x = np.concatenate((x_above, x_below), axis=0)\n",
    "labeled_data_y = np.concatenate((y_above, y_below), axis=0)\n",
    "\n",
    "not_labeled_data_x = train_split_x[~np.isin(np.arange(len(train_split_x)), np.where(scores >= threshold_above)[0]) & ~np.isin(np.arange(len(train_split_x)), np.where(scores <= threshold_below)[0])]\n",
    "not_labeled_data_y = train_split_y[~np.isin(np.arange(len(train_split_x)), np.where(scores >= threshold_above)[0]) & ~np.isin(np.arange(len(train_split_x)), np.where(scores <= threshold_below)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20fd27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a propensity model:\n",
    "propensity_model = MLPClassifier(hidden_layer_sizes=(10), max_iter=1000, random_state=42, early_stopping=True, validation_fraction=0.2, n_iter_no_change=10)\n",
    "propensity_train_x = np.concatenate((labeled_data_x, not_labeled_data_x), axis=0)\n",
    "propensity_train_y = np.concatenate((np.ones(len(labeled_data_x)), np.zeros(len(not_labeled_data_x))), axis=0)  # 1 for labeled, 0 for not labeled\n",
    "propensity_model.fit(train_split_x, train_split_y)\n",
    "# Predict propensity scores\n",
    "propensity_scores = propensity_model.predict_proba(train_split_x)[:, 1]  # get propensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95712bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the embedding of the labeled data vs the unlabeled data\n",
    "pca_labeled_data_x = pca.transform(labeled_data_x)\n",
    "pca_not_labeled_data_x = pca.transform(not_labeled_data_x)\n",
    "fig = px.scatter(x=pca_labeled_data_x[:, 0], y=pca_labeled_data_x[:, 1], color=labeled_data_y, title=\"PCA of the labeled data\")\n",
    "fig.add_trace(go.Scatter(x=pca_not_labeled_data_x[:, 0], y=pca_not_labeled_data_x[:, 1], mode='markers', name='Unlabeled Data', marker=dict(color='grey', size=5, symbol='x')))\n",
    "fig.update_layout(xaxis_title='PCA Component 1', yaxis_title='PCA Component 2')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_labeled_x, test_data_labeled_x, train_data_labeled_y, test_data_labeled_y = train_test_split(labeled_data_x, labeled_data_y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9544c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model on the labeled data\n",
    "labeled_data_selection_model = MLPClassifier(hidden_layer_sizes=(10), max_iter=50, random_state=42, early_stopping=True, validation_fraction=0.2, n_iter_no_change=10)\n",
    "labeled_data_selection_model.fit(train_data_labeled_x, train_data_labeled_y)\n",
    "scores_outcome_model = labeled_data_selection_model.predict_proba(test_data_labeled_x)\n",
    "print(\"ROC AUC Score (Labeled Data):\", roc_auc_score(test_data_labeled_y, scores_outcome_model[:, 1]))\n",
    "print(\"ROC AUC Score (all Data):\", roc_auc_score(test_split_y, labeled_data_selection_model.predict_proba(test_split_x)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7598dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_X = propensity_model.predict_proba(train_data_labeled_x)[:, 1]\n",
    "e_X = np.clip(e_X, 1e-3, 1 - 1e-3)\n",
    "T = labeled_data_selection_model.predict_proba(train_data_labeled_x)[:, 1]  # Assuming T is the treatment assignment, here we use the model's prediction as a proxy\n",
    "\n",
    "# Schritt 2: Gewicht berechnen\n",
    "weights = T / e_X + (1 - T) / (1 - e_X)\n",
    "\n",
    "# Schritt 3: Outcome-Model trainieren mit gewichteter Regression\n",
    "# z.B. sklearn: sample_weight=weights\n",
    "new_outcome_model = MLPClassifier(hidden_layer_sizes=(10), max_iter=1000, random_state=42, early_stopping=True, validation_fraction=0.2, n_iter_no_change=10)\n",
    "new_outcome_model.fit(np.hstack([train_data_labeled_x, T.reshape(-1, 1)]), train_data_labeled_y, sample_weight=weights)\n",
    "# Predict the outcome using the new outcome model\n",
    "scores_outcome_model = new_outcome_model.predict_proba(test_data_labeled_x)\n",
    "print(\"ROC AUC Score (Labeled Data):\", roc_auc_score(test_data_labeled_y, scores_outcome_model[:, 1]))\n",
    "print(\"ROC AUC Score (all Data):\", roc_auc_score(test_split_y, new_outcome_model.predict_proba(test_split_x)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700907fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.dr import DRLearner\n",
    "\n",
    "\n",
    "learner = DRLearner(model_propensity=propensity_model,\n",
    "                    model_regression=labeled_data_selection_model)\n",
    "learner.fit(Y, T, X)\n",
    "tau_hat = learner.effect(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
